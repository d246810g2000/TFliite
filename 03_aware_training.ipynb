{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03_aware_training\n",
    "* [1. Train a basic model for Cifar10](#1.-Train-a-basic-model-for-Cifar10)\n",
    "* [2. Optimization](#2.-Optimization)\n",
    "     - [2.1 Quantization](#2.1-Quantization)\n",
    "     - [2.2 Pruning](#2.2-Pruning)\n",
    "     - [2.3 Clustering](#2.3-Clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yJwIonXEVJo6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Dense, Activation, Flatten, Conv2D, MaxPooling2D, Reshape)\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psViY5PRDurp"
   },
   "source": [
    "## 1. Train a basic model for Cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "y_train.shape: (50000, 1)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# cifar10 中有將 data 先分為 train 和 test\n",
    "cifar10 = keras.datasets.cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train.shape:', y_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# x_train.shape: 四個維度：第 1 維度為筆數、第 2, 3 維度為影像大小 32*32、第 4 維度是 RGB 三原色，所以是 3\n",
    "# x_train 中有 50000 筆訓練資料，以及 x_test 中有 10000 筆的測試資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 記得轉成 'float32'\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# 將 features (照片影像特徵值) 標準化，可以提高模型預測的準確度，並且更快收斂\n",
    "x_train /= 255  # rescaling\n",
    "x_test /= 255   # rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (50000, 10)\n",
      "y_test shape: (10000, 10)\n",
      "y_test.argmax(1) shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# 將訓練資料與測試資料的 label，進行 Onehot encoding 轉換\n",
    "num_classes = 10\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "y_train = np.eye(num_classes, dtype='float32')[y_train[:, 0]]\n",
    "y_test = np.eye(num_classes, dtype='float32')[y_test[:, 0]]\n",
    "\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "print('y_test.argmax(1) shape:', y_test.argmax(1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pbY-KGMPvbW9"
   },
   "outputs": [],
   "source": [
    "# 選擇 Keras 的 API 寫法\n",
    "inputs = Input(shape=x_train.shape[1:])\n",
    "\n",
    "# 第一層\n",
    "# 建立卷積層，設定32個3*3的filters\n",
    "# 設定ReLU為激活函數。\n",
    "x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "\n",
    "# 第二層 - 卷積層 + 池化層\n",
    "x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# 第三層 - 卷積層\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "\n",
    "# 第四層 - 卷積層 + 池化層\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# 建立分類模型 (MLP) : 平坦層 + 輸出層 (10)\n",
    "x = Flatten()(x)\n",
    "outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 81,578\n",
      "Trainable params: 81,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 81,578\n",
      "Trainable params: 81,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 20\n",
    "learning_rate = 1e-3\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 - 5s - loss: 2.1245 - accuracy: 0.3247 - val_loss: 2.0897 - val_accuracy: 0.3630\n",
      "Epoch 2/20\n",
      "50000/50000 - 3s - loss: 2.0091 - accuracy: 0.4462 - val_loss: 1.9548 - val_accuracy: 0.5024\n",
      "Epoch 3/20\n",
      "50000/50000 - 3s - loss: 1.9443 - accuracy: 0.5139 - val_loss: 1.9266 - val_accuracy: 0.5303\n",
      "Epoch 4/20\n",
      "50000/50000 - 3s - loss: 1.8940 - accuracy: 0.5651 - val_loss: 1.8819 - val_accuracy: 0.5762\n",
      "Epoch 5/20\n",
      "50000/50000 - 3s - loss: 1.8581 - accuracy: 0.6005 - val_loss: 1.8559 - val_accuracy: 0.6039\n",
      "Epoch 6/20\n",
      "50000/50000 - 3s - loss: 1.8298 - accuracy: 0.6297 - val_loss: 1.8454 - val_accuracy: 0.6123\n",
      "Epoch 7/20\n",
      "50000/50000 - 3s - loss: 1.8140 - accuracy: 0.6448 - val_loss: 1.8372 - val_accuracy: 0.6233\n",
      "Epoch 8/20\n",
      "50000/50000 - 3s - loss: 1.7927 - accuracy: 0.6673 - val_loss: 1.8238 - val_accuracy: 0.6343\n",
      "Epoch 9/20\n",
      "50000/50000 - 3s - loss: 1.7780 - accuracy: 0.6821 - val_loss: 1.8215 - val_accuracy: 0.6355\n",
      "Epoch 10/20\n",
      "50000/50000 - 3s - loss: 1.7627 - accuracy: 0.6968 - val_loss: 1.7864 - val_accuracy: 0.6735\n",
      "Epoch 11/20\n",
      "50000/50000 - 3s - loss: 1.7555 - accuracy: 0.7044 - val_loss: 1.7893 - val_accuracy: 0.6703\n",
      "Epoch 12/20\n",
      "50000/50000 - 3s - loss: 1.7497 - accuracy: 0.7103 - val_loss: 1.7864 - val_accuracy: 0.6734\n",
      "Epoch 13/20\n",
      "50000/50000 - 3s - loss: 1.7397 - accuracy: 0.7209 - val_loss: 1.7897 - val_accuracy: 0.6685\n",
      "Epoch 14/20\n",
      "50000/50000 - 3s - loss: 1.7306 - accuracy: 0.7298 - val_loss: 1.7677 - val_accuracy: 0.6893\n",
      "Epoch 15/20\n",
      "50000/50000 - 3s - loss: 1.7251 - accuracy: 0.7346 - val_loss: 1.7813 - val_accuracy: 0.6780\n",
      "Epoch 16/20\n",
      "50000/50000 - 3s - loss: 1.7166 - accuracy: 0.7440 - val_loss: 1.7738 - val_accuracy: 0.6854\n",
      "Epoch 17/20\n",
      "50000/50000 - 3s - loss: 1.7097 - accuracy: 0.7506 - val_loss: 1.7612 - val_accuracy: 0.6981\n",
      "Epoch 18/20\n",
      "50000/50000 - 3s - loss: 1.7105 - accuracy: 0.7495 - val_loss: 1.7543 - val_accuracy: 0.7061\n",
      "Epoch 19/20\n",
      "50000/50000 - 3s - loss: 1.7026 - accuracy: 0.7573 - val_loss: 1.7622 - val_accuracy: 0.6976\n",
      "Epoch 20/20\n",
      "50000/50000 - 3s - loss: 1.7015 - accuracy: 0.7589 - val_loss: 1.7521 - val_accuracy: 0.7065\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RyIKnbVZafIH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.7065\n",
      "Saved baseline model to: /tmp/tmpxew3o8lm.h5\n"
     ]
    }
   ],
   "source": [
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    x_test, y_test, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_model_optimization\n",
      "  Using cached https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy~=1.14 in /opt/conda/lib/python3.7/site-packages (from tensorflow_model_optimization) (1.16.5)\n",
      "Requirement already satisfied: six~=1.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow_model_optimization) (1.13.0)\n",
      "Collecting dm-tree~=0.1.1\n",
      "  Using cached https://files.pythonhosted.org/packages/6b/d9/6d88e8d32bb454c4ef8f50c62714b0eb20170f4c1d2cd316e0d99755405e/dm_tree-0.1.5-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Installing collected packages: dm-tree, tensorflow-model-optimization\n",
      "Successfully installed dm-tree-0.1.5 tensorflow-model-optimization-0.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_model_optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(interpreter, x_test, y_test):\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "    # Run predictions on every image in the \"test\" dataset.\n",
    "    prediction_digits = []\n",
    "    for i, test_image in enumerate(x_test):\n",
    "        test_image = np.expand_dims(test_image, axis=0).astype('float32')\n",
    "        interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "        # Run inference.\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # probability.\n",
    "        output = interpreter.tensor(output_index)\n",
    "        digit = np.argmax(output()[0])\n",
    "        prediction_digits.append(digit)\n",
    "\n",
    "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "    prediction_digits = np.array(prediction_digits)\n",
    "    accuracy = (prediction_digits == y_test.argmax(-1)).mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "    # Returns size of gzipped model, in bytes.\n",
    "    import os\n",
    "    import zipfile\n",
    "\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "\n",
    "    return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "quantized_model = quantize_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "quantize_layer (QuantizeLaye (None, 32, 32, 3)         3         \n",
      "_________________________________________________________________\n",
      "quant_conv2d (QuantizeWrappe (None, 30, 30, 32)        963       \n",
      "_________________________________________________________________\n",
      "quant_conv2d_1 (QuantizeWrap (None, 28, 28, 32)        9315      \n",
      "_________________________________________________________________\n",
      "quant_max_pooling2d (Quantiz (None, 14, 14, 32)        1         \n",
      "_________________________________________________________________\n",
      "quant_conv2d_2 (QuantizeWrap (None, 12, 12, 64)        18627     \n",
      "_________________________________________________________________\n",
      "quant_conv2d_3 (QuantizeWrap (None, 10, 10, 64)        37059     \n",
      "_________________________________________________________________\n",
      "quant_max_pooling2d_1 (Quant (None, 5, 5, 64)          1         \n",
      "_________________________________________________________________\n",
      "quant_flatten (QuantizeWrapp (None, 1600)              1         \n",
      "_________________________________________________________________\n",
      "quant_dense (QuantizeWrapper (None, 10)                16015     \n",
      "=================================================================\n",
      "Total params: 81,985\n",
      "Trainable params: 81,578\n",
      "Non-trainable params: 407\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 'quantize_model' requires a recompile.\n",
    "quantized_model.compile(optimizer='adam',\n",
    "                        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "quantized_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "50000/50000 [==============================] - 9s 181us/sample - loss: 1.7044 - accuracy: 0.7554 - val_loss: 1.7498 - val_accuracy: 0.7092\n",
      "Epoch 2/3\n",
      "50000/50000 [==============================] - 8s 156us/sample - loss: 1.6914 - accuracy: 0.7689 - val_loss: 1.7652 - val_accuracy: 0.6943\n",
      "Epoch 3/3\n",
      "50000/50000 [==============================] - 8s 157us/sample - loss: 1.6882 - accuracy: 0.7721 - val_loss: 1.7547 - val_accuracy: 0.7037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f33a1da5400>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=3,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.7065\n",
      "Quant test accuracy: 0.7037\n"
     ]
    }
   ],
   "source": [
    "_, quantized_model_accuracy = quantized_model.evaluate(\n",
    "    x_test, y_test, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "print('Quant test accuracy:', quantized_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved quantized Keras model to: /tmp/tmpa669484e.h5\n"
     ]
    }
   ],
   "source": [
    "_, quantized_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(quantized_model, quantized_keras_file, include_optimizer=False)\n",
    "print('Saved quantized Keras model to:', quantized_keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved quantized tflite model to: /tmp/tmpvsnhhdmd.tflite\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(quantized_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_tflite_model = converter.convert()\n",
    "\n",
    "_, quantized_tflite_file = tempfile.mkstemp('.tflite')\n",
    "with open(quantized_tflite_file, 'wb') as f:\n",
    "    f.write(quantized_tflite_model)\n",
    "    \n",
    "print('Saved quantized tflite model to:', quantized_tflite_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped baseline Keras model: 307417.00 bytes\n",
      "Size of gzipped quantized Keras model: 311219.00 bytes\n",
      "Size of gzipped quantized TFlite model: 72155.00 bytes\n",
      "see 4.260508627260758x smaller model from quantization\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped quantized Keras model: %.2f bytes\" % (get_gzipped_model_size(quantized_keras_file)))\n",
    "print(\"Size of gzipped quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_tflite_file)))\n",
    "print(f\"see {get_gzipped_model_size(keras_file)/get_gzipped_model_size(quantized_tflite_file)}x smaller model from quantization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See persistence of accuracy from TF to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.7065\n",
      "Quant TF test accuracy: 0.7037\n",
      "Quant TFLite test_accuracy: 0.7059\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter, x_test, y_test)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "print('Quant TF test accuracy:', quantized_model_accuracy)\n",
    "print('Quant TFLite test_accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the quantized model.\n",
    "with open('tflite_model/mobilenet_aware_quant.tflite', 'wb') as f:\n",
    "    f.write(quantized_tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute end step to finish pruning after 3 epochs.\n",
    "epochs = 3\n",
    "num_images = x_train.shape[0]\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                             final_sparsity=0.80, \n",
    "                                                             begin_step=0,\n",
    "                                                             end_step=end_step)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:200: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    }
   ],
   "source": [
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "pruned_model = prune_low_magnitude(model, **pruning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "oq6blGjgFDCW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d ( (None, 30, 30, 32)        1762      \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d_1 (None, 28, 28, 32)        18466     \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 14, 14, 32)        1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d_2 (None, 12, 12, 64)        36930     \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d_3 (None, 10, 10, 64)        73794     \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 5, 5, 64)          1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_flatten  (None, 1600)              1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense (P (None, 10)                32012     \n",
      "=================================================================\n",
      "Total params: 162,967\n",
      "Trainable params: 81,578\n",
      "Non-trainable params: 81,389\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 'prune_low_magnitude' requires a recompile.\n",
    "pruned_model.compile(optimizer='adam',\n",
    "                     loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "pruned_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "_PHDGJryE31X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "   64/50000 [..............................] - ETA: 36:34 - loss: 1.8101 - accuracy: 0.6406WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.279299). Check your callbacks.\n",
      "50000/50000 [==============================] - 9s 186us/sample - loss: 1.7015 - accuracy: 0.7592 - val_loss: 1.7517 - val_accuracy: 0.7064\n",
      "Epoch 2/3\n",
      "50000/50000 [==============================] - 6s 126us/sample - loss: 1.7052 - accuracy: 0.7581 - val_loss: 1.7518 - val_accuracy: 0.7111\n",
      "Epoch 3/3\n",
      "50000/50000 [==============================] - 6s 126us/sample - loss: 1.6910 - accuracy: 0.7735 - val_loss: 1.7430 - val_accuracy: 0.7187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f32d842aef0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "  \n",
    "pruned_model.fit(x_train, y_train,\n",
    "                 batch_size=batch_size, \n",
    "                 epochs=epochs, \n",
    "                 validation_data=(x_test, y_test),\n",
    "                 callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-byC2lYlMkfN"
   },
   "source": [
    "For this example, there is minimal loss in test accuracy after pruning, compared to the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "6bMFTKSSHyyZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.7065\n",
      "Pruned test accuracy: 0.7187\n"
     ]
    }
   ],
   "source": [
    "_, pruned_model_accuracy = pruned_model.evaluate(\n",
    "   x_test, y_test, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy) \n",
    "print('Pruned test accuracy:', pruned_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "w7fztWsAOHTz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned Keras model to: /tmp/tmpkxpi6fn1.h5\n"
     ]
    }
   ],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
    "\n",
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', pruned_keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "uIKxSSHmrJSa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned TFLite model to: /tmp/tmpcie5r32q.tflite\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(pruned_tflite_file, 'wb') as f:\n",
    "    f.write(pruned_tflite_model)\n",
    "\n",
    "print('Saved pruned TFLite model to:', pruned_tflite_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped baseline Keras model: 307417.00 bytes\n",
      "Size of gzipped pruned Keras model: 99917.00 bytes\n",
      "Size of gzipped pruned TFlite model: 96992.00 bytes\n",
      "see 3.169508825470142x smaller model from pruning\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
    "print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))\n",
    "print(f\"see {get_gzipped_model_size(keras_file)/get_gzipped_model_size(pruned_tflite_file)}x smaller model from pruning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pruned model.\n",
    "with open('tflite_model/mobilenet_aware_pruned.tflite', 'wb') as f:\n",
    "    f.write(pruned_tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8D7WnFF5DZR"
   },
   "source": [
    "### Create a smaller model from combining pruning and quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "jy_Lgfh8VkyX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved quantized and pruned TFLite model to: /tmp/tmpc9_nur2g.tflite\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_and_pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, quantized_and_pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
    "    f.write(quantized_and_pruned_tflite_model)\n",
    "\n",
    "print('Saved quantized and pruned TFLite model to:', quantized_and_pruned_tflite_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped baseline Keras model: 307417.00 bytes\n",
      "Size of gzipped quantized and pruned TFlite model: 29974.00 bytes\n",
      "see 10.256121972376059x smaller model from pruning adn quantization\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped quantized and pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))\n",
    "print(f\"see {get_gzipped_model_size(keras_file)/get_gzipped_model_size(quantized_and_pruned_tflite_file)}x smaller model from pruning adn quantization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pruned and quantized model.\n",
    "with open('tflite_model/mobilenet_aware_quantxpruned.tflite', 'wb') as f:\n",
    "    f.write(quantized_and_pruned_tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEYsyYVqNgeY"
   },
   "source": [
    "### See persistence of accuracy from TF to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "VqQTyqz4NsWd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.7065\n",
      "Pruned TF test accuracy: 0.7187\n",
      "Pruned and quantized TFLite test_accuracy: 0.7194\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=quantized_and_pruned_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter, x_test, y_test)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "print('Pruned TF test accuracy:', pruned_model_accuracy)\n",
    "print('Pruned and quantized TFLite test_accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model for clustering.\n",
    "clustering_params = {\n",
    "  'number_of_clusters': 16,\n",
    "  'cluster_centroids_init': tfmot.clustering.keras.CentroidInitialization.LINEAR\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
    "clustered_model = cluster_weights(model, **clustering_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "cluster_conv2d (ClusterWeigh (None, 30, 30, 32)        912       \n",
      "_________________________________________________________________\n",
      "cluster_conv2d_1 (ClusterWei (None, 28, 28, 32)        9264      \n",
      "_________________________________________________________________\n",
      "cluster_max_pooling2d (Clust (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "cluster_conv2d_2 (ClusterWei (None, 12, 12, 64)        18512     \n",
      "_________________________________________________________________\n",
      "cluster_conv2d_3 (ClusterWei (None, 10, 10, 64)        36944     \n",
      "_________________________________________________________________\n",
      "cluster_max_pooling2d_1 (Clu (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "cluster_flatten (ClusterWeig (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "cluster_dense (ClusterWeight (None, 10)                16026     \n",
      "=================================================================\n",
      "Total params: 81,658\n",
      "Trainable params: 282\n",
      "Non-trainable params: 81,376\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Use smaller learning rate for fine-tuning clustered model\n",
    "learning_rate = 1e-5\n",
    "optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "clustered_model.compile(optimizer=optimizer,\n",
    "                        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "clustered_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "50000/50000 [==============================] - 10s 204us/sample - loss: 2.1258 - accuracy: 0.3322 - val_loss: 2.0163 - val_accuracy: 0.4433\n",
      "Epoch 2/3\n",
      "50000/50000 [==============================] - 9s 184us/sample - loss: 1.9189 - accuracy: 0.5403 - val_loss: 1.8899 - val_accuracy: 0.5694\n",
      "Epoch 3/3\n",
      "50000/50000 [==============================] - 9s 184us/sample - loss: 1.8403 - accuracy: 0.6190 - val_loss: 1.8418 - val_accuracy: 0.6181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f32780bd860>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=3,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.7065\n",
      "Clustered test accuracy: 0.6181\n"
     ]
    }
   ],
   "source": [
    "_, clustered_model_accuracy = clustered_model.evaluate(\n",
    "  x_test, y_test, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "print('Clustered test accuracy:', clustered_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved clustered keras model to: /tmp/tmpx_rfzbhf.h5\n"
     ]
    }
   ],
   "source": [
    "model_for_export = tfmot.clustering.keras.strip_clustering(clustered_model)\n",
    "\n",
    "_, clustered_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model_for_export, clustered_keras_file, include_optimizer=False)\n",
    "print('Saved clustered keras model to:', clustered_keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved clustered TFLite model to: /tmp/tmpyd8vmnrt.tflite\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "clustered_tflite_model = converter.convert()\n",
    "\n",
    "_, clustered_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(clustered_tflite_file, 'wb') as f:\n",
    "    f.write(clustered_tflite_model)\n",
    "\n",
    "print('Saved clustered TFLite model to:', clustered_tflite_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped baseline Keras model: 307417.00 bytes\n",
      "Size of gzipped clustered Keras model: 29958.00 bytes\n",
      "Size of gzipped clustered TFlite model: 27805.00 bytes\n",
      "see 11.05617694659234x smaller model from clustering\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped clustered Keras model: %.2f bytes\" % (get_gzipped_model_size(clustered_keras_file)))\n",
    "print(\"Size of gzipped clustered TFlite model: %.2f bytes\" % (get_gzipped_model_size(clustered_tflite_file)))\n",
    "print(f\"see {get_gzipped_model_size(keras_file)/get_gzipped_model_size(clustered_tflite_file)}x smaller model from clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the clustered model.\n",
    "with open('tflite_model/mobilenet_aware_clustered.tflite', 'wb') as f:\n",
    "    f.write(clustered_tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8D7WnFF5DZR"
   },
   "source": [
    "### Create a smaller model from combining clustering and quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved quantized and clustered TFLite model to: /tmp/tmprgl8q3ak.tflite\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_and_clustered_tflite_model = converter.convert()\n",
    "\n",
    "_, quantized_and_clustered_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quantized_and_clustered_tflite_file, 'wb') as f:\n",
    "    f.write(quantized_and_clustered_tflite_model)\n",
    "\n",
    "print('Saved quantized and clustered TFLite model to:', quantized_and_clustered_tflite_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped baseline Keras model: 307417.00 bytes\n",
      "Size of gzipped quantized and clustered TFlite model: 21243.00 bytes\n",
      "see 14.47144941863202x smaller model from clustering and quantization\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size of gzipped baseline Keras model: {get_gzipped_model_size(keras_file):.2f} bytes\")\n",
    "print(f\"Size of gzipped quantized and clustered TFlite model: {get_gzipped_model_size(quantized_and_clustered_tflite_file):.2f} bytes\")\n",
    "print(f\"see {get_gzipped_model_size(keras_file)/get_gzipped_model_size(quantized_and_clustered_tflite_file)}x smaller model from clustering and quantization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pruned and quantized model.\n",
    "with open('tflite_model/mobilenet_aware_quantxclustered.tflite', 'wb') as f:\n",
    "    f.write(quantized_and_clustered_tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEYsyYVqNgeY"
   },
   "source": [
    "### See persistence of accuracy from TF to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "VqQTyqz4NsWd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.7065\n",
      "Clustered TF test accuracy: 0.6181\n",
      "Clustered and quantized TFLite test_accuracy: 0.6117\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=quantized_and_clustered_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter, x_test, y_test)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "print('Clustered TF test accuracy:', clustered_model_accuracy)\n",
    "print('Clustered and quantized TFLite test_accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pruning_with_keras.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
